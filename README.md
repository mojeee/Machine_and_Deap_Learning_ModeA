Natural Language Processing with Disaster Tweets
Version 1.0
==================================================================
#### Author: Mojtaba Amini ####
#### Email: Mojtaba.amini.1995@gmail.com ####
#### Supervisor: GIOVANNI DA SAN MARTINO
#### Universita di Padova
#### Machine and Deep Learning Mode A. Project

Abstract
-------------------------


Twitter has become an important communication channel in times of emergency.
The ubiquitousness of smartphones enables people to announce an emergency they’re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).

But, it’s not always clear whether a person’s words are actually announcing a disaster. Take this example:

<img src="https://storage.googleapis.com/kaggle-media/competitions/tweet_screenshot.png" width="300" height="600" align="left"/> 
<br/><br/>
The author explicitly uses the word “ABLAZE” but means it metaphorically. This is clear to a human right away, especially with the visual aid. But it’s less clear to a machine.

In this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. You’ll have access to a dataset of 10,000 tweets that were hand classified. If this is your first time working on an NLP problem, we've created a quick tutorial to get you up and running.

Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive.

Acknowledgments
This dataset was created by the company figure-eight and originally shared on their ‘Data For Everyone’ website here.

Tweet source: https://twitter.com/AnyOtherAnnaK/status/629195955506708480
<br/><br/>
<br/><br/>
<br/><br/>
<br/><br/>
<br/><br/>
<br/>


For each record, it is provided:

Files
-------------------------
The dataset includes the following files:

Files  | Description
------------- | -------------
'README.txt'  | 
'main.py'  | Almost all the essential function for post-processing is provided in each section. Also, there is enough comment for each section.
'.png or .jpg in nlp-getting-started folder'  | Images are used for wordcloud, absolutely not all of them
'predict.csv'  | The output of prediction for test data
'test.csv'  | Test Data
'sample_submission.csv'  | Sample of submission file in the kaggle
'train.csv'  | Train data 




Notes
--------------------------
* A new user should read 'comments' carefully.


Mojtaba Amini. January 2022.
